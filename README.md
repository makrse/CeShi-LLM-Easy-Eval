# 介绍
这是我作为兴趣爱好的第一个小项目。这个项目的起因是，因为对于普通用户来说，想要了解如何基准测试LLM（大型语言模型）非常让人困惑，通常需要浏览很多视频、文档等资料。
目前主要集中在使用gguf模型和GPU（CUDA）。

# 如何使用：

1. 使用Anaconda[conda]或Python venv创建环境，并选择：
  - Python版本 3.10（理想版本）
  - Python版本 3.10.8（我现在使用的版本）（我没有测试其他版本的Python）
2. 安装llama.cpp（Python） [安装过程中出现的错误无法一一列举，每个系统可能会遇到不同的错误，以后我可能会一个一个进行把这些困惑给解决方案]
3. 下载DeepEval的仓库文件，只下载主文件夹，将其放入空文件夹中。
4. 使用以下命令安装DeepEval：
  - pip install -U deepeval==2.1.2
5. 使用我的仓库，将其放到主文件夹中，并替换文件。
  - 打开你想运行的[基准测试类型].py文件，我建议将gguf模型放到主文件夹中，根据需要修改参数以适应你的用例。
6. 运行脚本：
  - py 想运行的测试.py
# 最终说明： 

感谢DeepEval和llama.cpp团队的巨大贡献。
我会在了解到其他基准测试类型的使用情况后进行更新，因为有很多不同的类型，尝试做所有的测试可能会消耗时间和电力，而且基准数据集的格式可能不太规范，每种类型都有其缺点。
如果你使用了我的仓库并觉得它有用，请给我反馈，并别忘了提到这个仓库，这会让我觉得我可以做更多的事情来分享。如果你有任何需求，可以给我发个提醒，我会在空闲时间查看。
做这个对一位专家可能特别简单，我是在学习中同时想提供给大家一点贡献。
